{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Training on GPU\")\n",
    "    torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "else:\n",
    "    print(\"Training on CPU\")\n",
    "print(\"\")\n",
    "import os\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from functools import wraps\n",
    "\n",
    "# # Путь к лог-файлу\n",
    "# log_file_path = \".\\\\execution_time_log.txt\"\n",
    "\n",
    "# # Декоратор для измерения времени выполнения и логирования\n",
    "# def log_execution_time(func):\n",
    "#     @wraps(func)\n",
    "#     def wrapper(*args, **kwargs):\n",
    "#         # Получаем имя функции\n",
    "#         function_name = func.__name__\n",
    "\n",
    "#         # Начинаем замер времени выполнения\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         # Выполняем функцию\n",
    "#         result = func(*args, **kwargs)\n",
    "\n",
    "#         # Рассчитываем время выполнения\n",
    "#         execution_time = time.time() - start_time\n",
    "\n",
    "#         # Записываем в лог\n",
    "#         with open(log_file_path, \"a\") as log_file:\n",
    "#             log_file.write(f\"Function: {function_name}, Execution Time: {execution_time:.6f} seconds\\n\")\n",
    "\n",
    "#         return result\n",
    "\n",
    "#     return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.Configurator as configurator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configurator.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_sgn = config[\"pth_sgn\"]\n",
    "PATH_TO_INPUT = config[\"PATH_TO_INPUT\"]\n",
    "PATH_TO_RESULTS = config[\"PATH_TO_RESULTS\"]\n",
    "PATH_TO_TRUEMASKS = config[\"PATH_TO_TRUEMASKS\"]\n",
    "PATH_TO_EXPMASKS = config[\"PATH_TO_EXPMASKS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"gaze_data_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_data_path = {}\n",
    "for key, value in config[\"gaze_data_file\"].items():\n",
    "    gaze_data_path[key] = f\"{PATH_TO_INPUT}{value}\"\n",
    "input_path = f\"{PATH_TO_INPUT}{config[\"input_video\"]}\"\n",
    "output_path = f\"{PATH_TO_RESULTS}{config[\"output_video\"]}\"\n",
    "output_dataframe = (\n",
    "    f\"{PATH_TO_RESULTS}{config[\"output_dataframe\"]}\"\n",
    ")\n",
    "output_dataframe_all = (\n",
    "    f\"{PATH_TO_RESULTS}{config[\"output_dataframe_all\"]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yolo_model_wheight = config[\"Yolo_model_wheight\"]\n",
    "sam2_checkpoint = config[\"sam2_checkpoint\"]\n",
    "sam_model_weight = config[\"sam_model_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_classes = config[\"segmentation_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframes_for_segmentation(gaze_data_path: Dict[str, str]):\n",
    "    \"\"\"\n",
    "    Читает данные о взгляде из CSV файлов и нормализует индекс мирового пространства.\n",
    "\n",
    "    Params:\n",
    "        gaze_data_path (Dict[str, str]): Словарь, где ключи - метки данных, а значения - пути к CSV файлам.\n",
    "\n",
    "    Returns:\n",
    "        df (Dict[str, pd.DataFrame]): Словарь, где ключи - метки данных, а значения - соответствующие DataFrame.\n",
    "    \"\"\"\n",
    "    df = {}  # Инициализация словаря для хранения DataFrame\n",
    "\n",
    "    # Проходим по всем меткам данных и загружаем соответствующие CSV файлы\n",
    "    for df_label in gaze_data_path.keys():\n",
    "        # Читаем CSV файл в DataFrame\n",
    "        df[df_label] = pd.read_csv(gaze_data_path[df_label])\n",
    "\n",
    "        # Нормализуем индекс мирового пространства\n",
    "        df[df_label] = df[df_label].assign(\n",
    "            world_index=df[df_label][\"world_index\"] - min(df[df_label][\"world_index\"])\n",
    "        )\n",
    "\n",
    "    return df  # Возвращаем словарь с DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_data = read_dataframes_for_segmentation(gaze_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация предикторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"Yolo_model_wheight\"] != \"\" and config[\"sam2_checkpoint\"] != \"\" and config[\"sam_model_weight\"] != \"\":\n",
    "    # Инициализация ЙОЛЫ\n",
    "    yolo_model = YOLO(Yolo_model_wheight)\n",
    "    yolo_model.to(device)\n",
    "    print(\"initialized\")\n",
    "    ### Вписать в класс загрузку модели SAM2\n",
    "    model_cfg = os.path.basename(\"sam2_hiera_l.yaml\")\n",
    "\n",
    "    sam_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    "    sam_model = SAM2ImagePredictor(sam_model)\n",
    "    # Загружаем веса с настроенным энкодером/декодером\n",
    "    sam_model.model.load_state_dict(torch.load(sam_model_weight))\n",
    "    def predict_on_image(image):\n",
    "        \"\"\"\n",
    "        Выполняет предсказание на изображении с использованием модели и возвращает результаты.\n",
    "\n",
    "        Params:\n",
    "            yolo_model (str): модель YOLO pretrained\n",
    "            sam_model (str): модель SAM2 c весами энкодера/декодера\n",
    "            image (np.ndarray): Изображение (кадр), на котором будет выполнено предсказание.\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            boxes (Boxes): Объект с ограничивающими прямоугольниками (bbox) для обнаруженных объектов.\n",
    "            masks (Masks): Объект с сегментационными масками для обнаруженных объектов.\n",
    "            cls (int): Класс объекта\n",
    "            probs (np.ndarray): Вероятности классов для каждого обнаруженного объекта.\n",
    "        \"\"\"\n",
    "        results = yolo_model.predict(source=image, conf=0.5, stream=True)\n",
    "\n",
    "        # Инициализация переменных для хранения результатов\n",
    "        boxes, masks, class_ids, probs = [], [], [], []\n",
    "\n",
    "        # Обрабатываем результаты предсказания YOLO\n",
    "        for r in results:\n",
    "            yolo_boxes = r.boxes\n",
    "            yolo_mask = r.masks.cpu().numpy() if r.masks is not None else None\n",
    "            yolo_probs = r.probs.cpu().numpy() if r.probs is not None else None\n",
    "            yolo_class_ids = r.boxes.cls.cpu().numpy()\n",
    "\n",
    "            for i, box in enumerate(yolo_boxes):\n",
    "                # # Преобразование бокса для SAM2\n",
    "                xyxy = box.xyxy[0].cpu().numpy()\n",
    "                input_box = np.array(\n",
    "                    [\n",
    "                        np.round(xyxy[0]),\n",
    "                        np.round(xyxy[1]),\n",
    "                        np.round(xyxy[2]),\n",
    "                        np.round(xyxy[3]),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                if len(input_box) > 0:\n",
    "                    # Предсказание масок с помощью SAM2\n",
    "                    sam_model.set_image(image)\n",
    "                    sam_masks, _, _ = sam_model.predict(\n",
    "                        box=input_box, multimask_output=False\n",
    "                    )\n",
    "\n",
    "                    # Выбираем первую маску, так как multimask_output=False\n",
    "                    masks.append(sam_masks[0])\n",
    "\n",
    "                else:\n",
    "                    masks.append(yolo_mask)\n",
    "\n",
    "                # Добавляем данные боксов и классов\n",
    "                # boxes.append(yolo_boxes)\n",
    "                class_ids.append(int(yolo_class_ids[i]))  # Добавляем класс\n",
    "                if yolo_probs is not None:\n",
    "                    probs.append(yolo_probs[i])\n",
    "\n",
    "        return {\"boxes\": yolo_boxes, \"masks\": masks, \"classes\": class_ids, \"probs\": probs}\n",
    "elif config[\"Yolo_model_wheight\"] != \"\":\n",
    "    # Инициализация ЙОЛЫ\n",
    "    yolo_model = YOLO(Yolo_model_wheight)\n",
    "    yolo_model.to(device)\n",
    "    print(\"initialized\")\n",
    "    def predict_on_image(image: np.ndarray):\n",
    "        \"\"\"\n",
    "        Выполняет предсказание на изображении с использованием модели YOLO (детекции или сегментации)\n",
    "\n",
    "        Params:\n",
    "        model_path (str):\n",
    "        Путь до модели сегментации YOLO 8/9/11 или детекции YOLO 8/9/10/11\n",
    "\n",
    "        image (np.ndarray):\n",
    "        Массив изображения (кадра), на котором модель будет выполнять предсказания\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            boxes (np.ndarray): возвращает боксы в формате xyxy\n",
    "\n",
    "            masks (np.ndarray): возвращает маски\n",
    "\n",
    "            probs (np.ndarray): возвращает параметр conf\n",
    "\n",
    "            cls (np.ndarray): возвращает класс\n",
    "        \"\"\"\n",
    "\n",
    "        # Инициализация переменных для хранения результатов\n",
    "\n",
    "        results = yolo_model.predict(\n",
    "            source=image, conf=0.5,\n",
    "            stream=True)\n",
    "\n",
    "        boxes, masks, probs = None, None, None\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            masks = r.masks.data.cpu().numpy() if r.masks is not None else None\n",
    "            probs = r.probs if r.probs is not None else None\n",
    "            class_ids = list(int(x) for x in r.boxes.cls)\n",
    "\n",
    "\n",
    "        return {\"boxes\":boxes, \"masks\":masks, \"classes\":class_ids, \"probs\":probs}\n",
    "else:\n",
    "    raise Exception(\"no model wheight has been detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_prep(masks, class_ids, class_names, w, h):\n",
    "    \"\"\"\n",
    "    Подготавливает маски для наложения на изображение, изменяя их размер и формат.\n",
    "\n",
    "    Params:\n",
    "        masks: Объект масок, содержащий сегментационные маски.\n",
    "        boxes: Объекты ограничивающих прямоугольников для каждой маски.\n",
    "        class_names: Список названий классов для идентификации объектов.\n",
    "\n",
    "    Returns:\n",
    "        augmented_masks (dict): Словарь, где ключи - названия классов, а значения - подготовленные маски.\n",
    "    \"\"\"\n",
    "    # Инициализация словаря для хранения подготовленных масок\n",
    "    augmented_masks = {}\n",
    "\n",
    "    # Проверяем наличие масок\n",
    "    if masks is not None:\n",
    "        # Проходим по маскам и соответствующим ограничивающим прямоугольникам\n",
    "        for mask, id in zip(masks, class_ids):\n",
    "\n",
    "            # Преобразование маски в формат CV_8UC1\n",
    "            if mask.max() <= 1:\n",
    "                mask = (mask * 255).astype(np.uint8)\n",
    "            elif mask.max() > 1 and mask.max() <= 255:\n",
    "                mask = mask.astype(np.uint8)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Значения маски должны быть в диапазоне 0-1 или 0-255.\"\n",
    "                )\n",
    "\n",
    "            # Изменяем размер маски до оригинальной формы изображения\n",
    "            augmented_masks[class_names[id]] = cv2.resize(mask, (h, w))\n",
    "    else:\n",
    "        raise ValueError(\"Маски не найдены\")\n",
    "\n",
    "    return augmented_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import cv2\n",
    "\n",
    "\n",
    "def find_mask_raduis(mask):\n",
    "    \"\"\"\n",
    "    Находит минимальный и максимальный радиус от центра масс маски до её границы.\n",
    "\n",
    "    Params:\n",
    "        mask: Бинарная маска (np.ndarray), значения маски должны быть 0 или 255.\n",
    "\n",
    "    Returns:\n",
    "        center_mass: Координаты центра масс (x, y).\n",
    "        min_radius: Минимальный радиус (float).\n",
    "        max_radius: Максимальный радиус (float).\n",
    "    \"\"\"\n",
    "    # Преобразование маски в 8-битное изображение, если она не бинарная\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Находим момент маски\n",
    "    moments = cv2.moments(mask)\n",
    "    if moments[\"m00\"] == 0:\n",
    "        raise ValueError(\"Площадь маски равна нулю, невозможно вычислить центр масс.\")\n",
    "\n",
    "    # Вычисление координат центра масс\n",
    "    center_mass = (\n",
    "        int(moments[\"m10\"] / moments[\"m00\"]),\n",
    "        int(moments[\"m01\"] / moments[\"m00\"]),\n",
    "    )\n",
    "\n",
    "    # Получаем контуры маски\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        raise ValueError(\"Не найдены контуры маски.\")\n",
    "\n",
    "    # Извлекаем точки границы маски\n",
    "    contour_points = np.vstack(contours)\n",
    "\n",
    "    # Вычисляем расстояния от центра масс до всех точек границы\n",
    "    distances = [distance.euclidean(center_mass, point[0]) for point in contour_points]\n",
    "\n",
    "    # Минимальное и максимальное расстояние\n",
    "    min_radius = min(distances)\n",
    "    max_radius = max(distances)\n",
    "\n",
    "    return center_mass, min_radius, max_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_distance_to_contour(mask, point):\n",
    "    \"\"\"\n",
    "    Находит минимальное расстояние от заданной точки до ближайшего контура маски.\n",
    "\n",
    "    Params:\n",
    "        mask: Бинарная маска (np.ndarray), значения маски должны быть 0 или 255.\n",
    "        point: Координаты точки, для которой ищется расстояние (x, y).\n",
    "\n",
    "    Returns:\n",
    "        min_distance: Минимальное расстояние до ближайшего контура (float).\n",
    "    \"\"\"\n",
    "    # Преобразование маски в формат CV_8UC1, если это не так\n",
    "    if mask.max() <= 1:\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "    elif mask.max() > 1 and mask.max() <= 255:\n",
    "        mask = mask.astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Значения маски должны быть в диапазоне 0-1 или 0-255.\")\n",
    "\n",
    "    # Находим контуры маски\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) == 0:\n",
    "        raise ValueError(\"Контуры не найдены в маске.\")\n",
    "\n",
    "    # Инициализация минимального расстояния бесконечностью\n",
    "    min_distance = float(\"inf\")\n",
    "\n",
    "    # Проходим по всем контурам и находим минимальное расстояние до каждого\n",
    "    for contour in contours:\n",
    "        distance = cv2.pointPolygonTest(contour, point, True)\n",
    "        if distance < min_distance:\n",
    "            min_distance = abs(distance)  # Используем модуль расстояния\n",
    "\n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_point_touching_mask(mask, point, radius=5):\n",
    "    \"\"\"\n",
    "    Проверяет, пересекает ли круг вокруг точки маску.\n",
    "    Если хотя бы один пиксель внутри круга пересекает маску, возвращается True.\n",
    "\n",
    "    Params:\n",
    "        mask: Бинарная маска (np.ndarray), значения маски должны быть 0 или 255.\n",
    "        point: Координаты точки (x, y).\n",
    "        radius: Радиус круга вокруг точки (по умолчанию 5).\n",
    "\n",
    "    Returns:\n",
    "        True, если хотя бы один пиксель внутри радиуса круга пересекает маску, иначе False.\n",
    "    \"\"\"\n",
    "    x, y = point\n",
    "\n",
    "    # Преобразование маски в формат CV_8UC1, если это не так\n",
    "    if mask.max() <= 1:\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "    elif mask.max() > 1 and mask.max() <= 255:\n",
    "        mask = mask.astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Значения маски должны быть в диапазоне 0-1 или 0-255.\")\n",
    "\n",
    "    # Размеры изображения\n",
    "    h, w = mask.shape\n",
    "\n",
    "    # Создаем пустую маску того же размера, что и исходная\n",
    "    circle_mask = np.zeros_like(mask)\n",
    "\n",
    "    # Рисуем круг на новой маске в точке (x, y) с заданным радиусом\n",
    "    cv2.circle(circle_mask, (x, y), radius, 255, -1)\n",
    "\n",
    "    # Проверяем пересечение круговой маски с исходной маской\n",
    "    intersection = cv2.bitwise_and(mask, circle_mask)\n",
    "\n",
    "    # Если хотя бы один пиксель пересечения непустой, возвращаем True\n",
    "    return np.any(intersection > 0), np.sum(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gaze_points(w, h, masks, gaze_df, frame_number, radius): #exprimental\n",
    "    \"\"\"\n",
    "    Вычисляет и возвращает информацию о точках взгляда для текущего кадра,\n",
    "    проверяя их нахождение и касание с заданными масками объектов.\n",
    "\n",
    "    Params:\n",
    "        w (int): Ширина кадра.\n",
    "        h (int): Высота кадра.\n",
    "        masks (dict): Словарь масок объектов, где ключи - идентификаторы объектов,\n",
    "                      а значения - маски контуров.\n",
    "        gaze_df (pd.DataFrame): DataFrame с данными о взгляде, содержащий информацию\n",
    "                                о положении взгляда и метаданных для каждого кадра.\n",
    "        frame_number (int): Номер текущего кадра.\n",
    "        radius (int): Радиус для проверки касания точки взгляда с контуром маски.\n",
    "\n",
    "    Returns:\n",
    "        points_data (dict): Словарь, содержащий данные по точкам взгляда, где ключи -\n",
    "                            метки времени взгляда, а значения - информация о нахождении\n",
    "                            и касании точки взгляда с масками объектов.\n",
    "    \"\"\"\n",
    "\n",
    "    # Отбираем данные взгляда для текущего кадра по номеру кадра\n",
    "    gaze_points = gaze_df[gaze_df[\"world_index\"] == frame_number]\n",
    "    points_data = {}  # Инициализируем словарь для хранения данных по точкам взгляда\n",
    "\n",
    "    # Проходим по всем точкам взгляда в текущем кадре\n",
    "    for _, gaze_point in gaze_points.iterrows():\n",
    "        # Проверяем, что координаты точки взгляда не NaN\n",
    "        if not np.isnan(gaze_point[\"norm_pos_x\"]) and not np.isnan(\n",
    "            gaze_point[\"norm_pos_y\"]\n",
    "        ):\n",
    "            # Вычисляем координаты точки на кадре на основе нормализованных координат\n",
    "            center_x = int(gaze_point[\"norm_pos_x\"] * h)\n",
    "            center_y = int((1 - gaze_point[\"norm_pos_y\"]) * w)\n",
    "            point = (center_x, center_y)  # Определяем точку на кадре\n",
    "\n",
    "            # Создаем пустой датафрейм для хранения данных по текущей точке взгляда\n",
    "            point_data = pd.DataFrame(\n",
    "                columns=[\"mask\", \"is inside\", \"intersection\", \"normal\", \"radius_of_gaze\"]\n",
    "            )\n",
    "\n",
    "            # Проверяем взаимодействие точки взгляда с каждой маской\n",
    "            for mask_i in masks.keys():\n",
    "                # Создаем словарь для текущей маски\n",
    "                is_inside, _ = is_point_touching_mask(masks[mask_i], point, radius=1)\n",
    "                is_touching, intersection = is_point_touching_mask(\n",
    "                    masks[mask_i], point, radius=radius\n",
    "                )\n",
    "                normal = (\n",
    "                    0\n",
    "                    if is_inside\n",
    "                    else find_min_distance_to_contour(masks[mask_i], point)\n",
    "                )\n",
    "\n",
    "                # Проверяем, что все данные валидны (нет NaN или None)\n",
    "                if (\n",
    "                    not pd.isna(is_inside)\n",
    "                    and not pd.isna(is_touching)\n",
    "                    and not pd.isna(normal)\n",
    "                ):\n",
    "                    row_data = {\n",
    "                        \"mask\": [mask_i],\n",
    "                        \"is inside\": [is_inside],\n",
    "                        \"intersection\": [intersection],\n",
    "                        \"normal\": [normal],\n",
    "                        \"radius_of_gaze\": radius\n",
    "                    }\n",
    "                    # Добавляем данные для текущей маски как новую строку в DataFrame\n",
    "                    row_df = pd.DataFrame(row_data)\n",
    "                    point_data = pd.concat([point_data, row_df], ignore_index=True)\n",
    "\n",
    "                    # Добавляем данные по текущей точке взгляда в словарь\n",
    "                    points_data[gaze_point[\"gaze_timestamp\"]] = point_data\n",
    "\n",
    "    return points_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_function(masks, constant):\n",
    "    halo_rads = {}\n",
    "    for mask_i in masks.keys():\n",
    "        # Calculate the area of the mask\n",
    "        mask_area = np.sum(masks[mask_i])\n",
    "        center_mass, min_radius, max_radius = find_mask_raduis(masks[mask_i])\n",
    "        # Calculate the halo distance based on the mask area and the constant\n",
    "        halo_rads[mask_i] = min_radius * (constant**2) / mask_area\n",
    "\n",
    "    def calculate_probability(distance, mask_i):\n",
    "        if distance >= halo_rads[mask_i]:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1 - distance / halo_rads[mask_i]\n",
    "\n",
    "    return calculate_probability, halo_rads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def make_verdict(points_data, probability_function, frame_number):\n",
    "    \"\"\"\n",
    "    Формирует DataFrame с результатами анализа точек взгляда.\n",
    "\n",
    "    Parameters:\n",
    "        points_data (dict): Данные точек взгляда.\n",
    "        probability_function (function): Функция для вычисления вероятности на основе расстояния.\n",
    "        frame_number (int): Номер текущего кадра.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame с результатами анализа.\n",
    "    \"\"\"\n",
    "    verdict_data = []\n",
    "\n",
    "    # Проходим по каждому типу обработки\n",
    "    for processing_type, gaze_data in points_data.items():\n",
    "        # Проходим по каждой записи точки взгляда\n",
    "        for gaze_timestamp, point_df in gaze_data.items():\n",
    "            # Инициализируем данные для ближайшей и лучшей масок\n",
    "            nearest_data = {\n",
    "                \"mask\": \"None\",\n",
    "                \"prob\": 0,\n",
    "                \"is inside\": False,\n",
    "                \"intersection\": 0,\n",
    "                \"normal\": float(\"inf\"),\n",
    "            }\n",
    "            best_data = {\n",
    "                \"mask\": \"None\",\n",
    "                \"prob\": 0,\n",
    "                \"is inside\": False,\n",
    "                \"intersection\": 0,\n",
    "                \"normal\": float(\"inf\"),\n",
    "            }\n",
    "            other_mask_data = {}\n",
    "            radius_of_gaze = point_df.iloc[0][\"radius_of_gaze\"] if not point_df.empty else 0\n",
    "\n",
    "            if not point_df.empty:\n",
    "                # Проходим по каждой маске и вычисляем вероятность\n",
    "                for _, row in point_df.iterrows():\n",
    "                    prob = probability_function(row[\"normal\"], row[\"mask\"])\n",
    "\n",
    "                    # Сравниваем расстояние до ближайшей маски\n",
    "                    if row[\"normal\"] < nearest_data[\"normal\"]:\n",
    "                        nearest_data = {\n",
    "                            \"mask\": row[\"mask\"],\n",
    "                            \"prob\": prob,\n",
    "                            \"is inside\": row[\"is inside\"],\n",
    "                            \"normal\": row[\"normal\"],\n",
    "                            \"intersection\": row[\"intersection\"]\n",
    "                        }\n",
    "\n",
    "                    # Обновляем маску с максимальной вероятностью\n",
    "                    if prob > best_data[\"prob\"]:\n",
    "                        best_data = {\n",
    "                            \"mask\": row[\"mask\"],\n",
    "                            \"prob\": prob,\n",
    "                            \"is inside\": row[\"is inside\"],\n",
    "                            \"normal\": row[\"normal\"],\n",
    "                            \"intersection\": row[\"intersection\"]\n",
    "                        }\n",
    "\n",
    "                    # Сохраняем информацию о всех масках\n",
    "                    other_mask_data[row[\"mask\"]] = {\n",
    "                        \"is inside\": row[\"is inside\"],\n",
    "                        \"probability\": prob,\n",
    "                        \"normal\": row[\"normal\"],\n",
    "                        \"intersection\": row[\"intersection\"]\n",
    "                    }\n",
    "\n",
    "                # Удаляем информацию о лучшей и ближайшей масках из other_mask_data\n",
    "                other_mask_data.pop(best_data[\"mask\"], None)\n",
    "                if best_data[\"mask\"] != nearest_data[\"mask\"]:\n",
    "                    other_mask_data.pop(nearest_data[\"mask\"], None)\n",
    "\n",
    "            # Формируем строку для DataFrame\n",
    "            row_data = {\n",
    "                \"gaze_timestamp\": gaze_timestamp,\n",
    "                \"frame_number\": frame_number,\n",
    "                \"processing_type\": processing_type,\n",
    "                \"best_mask\": best_data[\"mask\"],\n",
    "                \"is_best_inside\": best_data[\"is inside\"],\n",
    "                \"best_intersection\": best_data[\"intersection\"],\n",
    "                \"best_probability\": best_data[\"prob\"],\n",
    "                \"best_normal\": best_data[\"normal\"],\n",
    "                \"nearest_mask\": nearest_data[\"mask\"],\n",
    "                \"nearest_intersection\": nearest_data[\"intersection\"],\n",
    "                \"nearest_probability\": nearest_data[\"prob\"],\n",
    "                \"nearest_normal\": nearest_data[\"normal\"],\n",
    "                \"radius_of_gaze\": radius_of_gaze,\n",
    "                \"other_mask_data\": json.dumps(other_mask_data),\n",
    "            }\n",
    "\n",
    "            # Добавляем строку в список\n",
    "            verdict_data.append(row_data)\n",
    "\n",
    "    # Преобразуем список словарей в DataFrame\n",
    "    verdict_df = pd.DataFrame(verdict_data)\n",
    "\n",
    "    return verdict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_plug(\n",
    "    gaze_data: Dict[str, pd.DataFrame],\n",
    "):\n",
    "    columns_to_check = [\n",
    "        \"gaze_timestamp\",\n",
    "        \"world_index\",\n",
    "        \"confidence\",\n",
    "        \"norm_pos_x\",\n",
    "        \"norm_pos_y\",\n",
    "    ]\n",
    "    if not bool(gaze_data):\n",
    "        raise Exception()\n",
    "    for gaze_df in gaze_data.values():\n",
    "        if not isinstance(gaze_df, pd.DataFrame()):\n",
    "            raise Exception(\n",
    "                \"safe_plug in segmentation_run_through\",\n",
    "                f\"Ошибка: gaze_df должен быть pd.DataFrame(), получено {type(gaze_df)}\",\n",
    "            )\n",
    "\n",
    "        if not all(x in columns_to_check for x in [*gaze_df]):\n",
    "            raise Exception(\n",
    "                \"safe_plug in segmentation_run_through\",\n",
    "                f\"Ошибка: gaze_df должен содержать определенные столбцы, отсутствоют {set(columns_to_check).difference({*gaze_df})}\",\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def save_experimental_mask_for_frame(p, w, h, frame_counter, masks_folder):\n",
    "    \"\"\"\n",
    "    Функция для получения мультиклассовой маски для определенного фрейма\n",
    "\n",
    "    Param:\n",
    "    frame_counter: номер фрейма\n",
    "    masks_folder: путь к истинным маскам\n",
    "\n",
    "    Return:\n",
    "    mask - истинная маска определенного фрейма\n",
    "    \"\"\"\n",
    "\n",
    "    # Инициализация пустой мультиклассовой маски\n",
    "    multi_class_mask = np.zeros((w, h), dtype=np.uint8)  # Используем (h, w)\n",
    "\n",
    "    # Заполнение мультиклассовой маски из словаря\n",
    "    for cl, mask in zip(p[\"classes\"], p[\"masks\"]):\n",
    "        if mask is not None:  # Проверка на наличие маски\n",
    "            original_shape = mask.shape\n",
    "\n",
    "            # Приведение маски к нужному размеру, если это необходимо\n",
    "            if original_shape != (w, h):\n",
    "                # Если размеры не совпадают, используем cv2.resize\n",
    "                mask = cv2.resize(mask, (h, w), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # Наложение класса на соответствующую область маски\n",
    "            multi_class_mask[mask > 0] = cl + 1  # Убедитесь, что cl начинается с 0\n",
    "\n",
    "    # Формируем имя файла маски\n",
    "    mask_filename = f\"{frame_counter:05d}.png\"\n",
    "    mask_path = os.path.join(masks_folder, mask_filename)\n",
    "\n",
    "    # Записываем изображение\n",
    "    cv2.imwrite(mask_path, multi_class_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.VideoLogger import VideoLogger\n",
    "from src.utils.VideoAggregation import VideoAggregation\n",
    "\n",
    "def segmentation_run_through(\n",
    "    video: VideoAggregation,\n",
    "    gaze_data: Dict[str, pd.DataFrame],\n",
    "    class_names: list,\n",
    "    Logger: VideoLogger,\n",
    "    predictor=predict_on_image,\n",
    "    path_to_masks=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Основная функция для сегментации видео, обработки и визуализации данных.\n",
    "    Процесс включает в себя следующие шаги:\n",
    "    чтение -> предсказание -> отрисовка маски и боксов -> отрисовка точек ->\n",
    "    запись кадра в выходное видео.\n",
    "\n",
    "    Params:\n",
    "        video (VideoAggregation): Объект VideoAggregation с инициализированными\n",
    "                                  исходными и выходными видеофайлами.\n",
    "        gaze_data (Dict[str, pd.DataFrame]): Словарь с данными взгляда, где ключи -\n",
    "                                             метки данных, а значения - соответствующие\n",
    "                                             DataFrame с координатами и метаданными.\n",
    "        class_names (list): Список классов сегментации.\n",
    "        Logger (VideoLogger): Объект для ведения логов.\n",
    "        predictor (function): Функция для предсказания сегментации.\n",
    "        path_to_masks (str): Путь для сохранения масок (по умолчанию None).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, pd.DataFrame: Два DataFrame с результатами обработки.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        safe_plug(gaze_data)\n",
    "    except Exception as e:\n",
    "        Logger.log(text_log_data=(\"error\", *e.args, \"До цикла обработки\"))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    constant = 2000\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            frame = video.read()  # Чтение текущего кадра\n",
    "\n",
    "            # Проверяем, достигнут ли конец видео\n",
    "            if video.end or video.enough():\n",
    "                break\n",
    "\n",
    "            if not video.already():\n",
    "                continue\n",
    "\n",
    "            # Предсказание сегментации\n",
    "            try:\n",
    "                prediction = predictor(frame)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                Logger.log(text_log_data=(\"error\", *e.args, f\"Кадр {video.frame_counter}\"))\n",
    "                continue\n",
    "\n",
    "            # Сохранение экспериментальной маски\n",
    "            if path_to_masks:\n",
    "                try:\n",
    "                    save_experimental_mask_for_frame(prediction, *frame.shape[:2], video.frame_counter, path_to_masks)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    Logger.log(text_log_data=(\"error\", *e.args, f\"Кадр {video.frame_counter}\"))\n",
    "\n",
    "            # Подготовка масок и расчёт вероятностей\n",
    "            try:\n",
    "                prediction[\"masks\"] = mask_prep(prediction[\"masks\"], prediction[\"classes\"], class_names, *frame.shape[:2])\n",
    "                pf, rads = probability_function(prediction[\"masks\"], constant)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                Logger.log(text_log_data=(\"error\", *e.args, f\"Кадр {video.frame_counter}\"))\n",
    "\n",
    "            print(rads)\n",
    "            # Визуализация результатов\n",
    "            try:\n",
    "                Logger.log(frame=frame, masks=prediction[\"masks\"], boxes=prediction[\"boxes\"], segment_rads = rads)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                Logger.log(text_log_data=(\"error\", *e.args, f\"Кадр {video.frame_counter}\"))\n",
    "\n",
    "            # Обработка данных взгляда\n",
    "            points_data = {}\n",
    "            for label, gaze_df in gaze_data.items():\n",
    "                try:\n",
    "                    Logger.log(frame=frame, gaze_data=gaze_df, label=label, frame_number=video.frame_counter)\n",
    "                    points_data[label] = calculate_gaze_points(*frame.shape[:2], prediction[\"masks\"], gaze_df, video.frame_counter, 5)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    Logger.log(text_log_data=(\"error\", *e.args, f\"Кадр {video.frame_counter}, Датафрейм {label}\"))\n",
    "\n",
    "                # Добавление данных о взглядах и сегментации\n",
    "                df = pd.concat([df, pd.DataFrame(make_verdict(points_data, pf, video.frame_counter))], ignore_index=True)\n",
    "\n",
    "            # Запись кадра в видео\n",
    "            video.write(frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            Logger.log(text_log_data=(\"error\", *e.args, video.frame_counter))\n",
    "            video.write(frame)\n",
    "        except KeyboardInterrupt:\n",
    "            Logger.log(text_log_data=(\"error\", \"Прерывание\", video.frame_counter))\n",
    "            video.release()\n",
    "            break\n",
    "\n",
    "    # Завершение работы\n",
    "    video.release()\n",
    "    print(\"Сегментация завершена.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Отключение предупреждений Pandas\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# Пример вызова функции\n",
    "\n",
    "Logger = VideoLogger(\n",
    "    \"MGF\",\n",
    "    seg_vis={\"classes\": segmentation_classes, \"alpha\": 0.4},\n",
    "    gaze_vis={\"classes\": gaze_data.keys()},\n",
    ")\n",
    "video = VideoAggregation(\n",
    "    input_path, output_path, Logger=Logger, frame_floor=4797, frame_cap=4799\n",
    ")\n",
    "df = segmentation_run_through(\n",
    "    video, gaze_data, segmentation_classes, Logger=Logger, path_to_masks=PATH_TO_EXPMASKS\n",
    ")\n",
    "df.to_csv(output_dataframe, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.MetricsCalculator as calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к папкам\n",
    "folder1 = PATH_TO_TRUEMASKS\n",
    "folder2 = PATH_TO_EXPMASKS\n",
    "\n",
    "# Найдем пересекающиеся имена файлов\n",
    "common_filenames = calc.find_common_filenames(folder1, folder2)\n",
    "\n",
    "# Загрузка изображений из каждой папки по общим именам файлов\n",
    "images1 = calc.load_images_by_filenames(folder1, common_filenames)\n",
    "images2 = calc.load_images_by_filenames(folder2, common_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def calculate_metrics(y_trues, y_preds,  classes, background_class=0):\n",
    "    # Инициализируем списки для хранения метрик\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    ious = []\n",
    "        # Проходим по каждой паре масок\n",
    "    for y_true, y_pred in zip(y_trues, y_preds):\n",
    "        # Проверяем, что размеры масок совпадают\n",
    "        if y_true.shape != y_pred.shape:\n",
    "            print(f\"Размеры масок не совпадают! Истинная: {y_true.shape}, Предсказанная: {y_pred.shape}\")\n",
    "            continue  # Пропускаем эту пару\n",
    "    # Проходим по каждой паре масок\n",
    "    for y_true, y_pred in zip(y_trues, y_preds):\n",
    "        # Приводим маски к формату 1D\n",
    "        y_true_flat = y_true.flatten()\n",
    "        y_pred_flat = y_pred.flatten()\n",
    "\n",
    "\n",
    "        # Рассчитываем precision, recall, F1-score с учетом всех классов, кроме фона\n",
    "        precision = precision_score(y_true_flat, y_pred_flat, average='weighted', labels=np.unique(y_true_flat[y_true_flat != background_class]), zero_division=0)\n",
    "        recall = recall_score(y_true_flat, y_pred_flat, average='weighted', labels=np.unique(y_true_flat[y_true_flat != background_class]), zero_division=0)\n",
    "        f1 = f1_score(y_true_flat, y_pred_flat, average='weighted', labels=np.unique(y_true_flat[y_true_flat != background_class]), zero_division=0)\n",
    "        iou = jaccard_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        \n",
    "        # Рассчитываем IoU (Intersection over Union) с учетом фона\n",
    "        # intersection = np.logical_and(y_true_flat, y_pred_flat).sum()\n",
    "        # union = np.logical_or(y_true_flat, y_pred_flat).sum()\n",
    "        # iou = intersection / union if union != 0 else 0\n",
    "\n",
    "        # Сохраняем результаты\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        ious.append(iou)\n",
    "\n",
    "    # Выводим средние метрики\n",
    "    avg_precision = np.mean(precisions) if precisions else 0\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    avg_f1 = np.mean(f1_scores) if f1_scores else 0\n",
    "    avg_iou = np.mean(ious) if ious else 0\n",
    "\n",
    "    print(\"Метрики по Weighted\")\n",
    "    print('\\n')\n",
    "    print(\"Precision:\", avg_precision)\n",
    "    print(\"Recall:\", avg_recall)\n",
    "    print(\"F1-Score:\", avg_f1)\n",
    "    print('\\n')\n",
    "    print(\"IoU:\", avg_iou)\n",
    "    print('\\n')\n",
    "\n",
    "    # Для визуализации матрицы путаницы\n",
    "    # Соединяем все истинные и предсказанные маски\n",
    "    y_true_all = np.concatenate([y.flatten() for y in y_trues])\n",
    "    y_pred_all = np.concatenate([y.flatten() for y in y_preds])\n",
    "\n",
    "    # Выводим отчет по классам, исключая фон\n",
    "    print(\"Classification Report (excluding background):\")\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=classes,labels=np.unique(y_true_all[y_true_all != background_class])))\n",
    "\n",
    "    # Рассчитываем матрицу путаницы\n",
    "    conf_matrix = confusion_matrix(y_true_all, y_pred_all, normalize='true', labels=np.unique(y_pred_all[y_pred_all != background_class]))\n",
    "\n",
    "    # Визуализируем матрицу путаницы\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap='Blues', \n",
    "                xticklabels=classes, #np.unique(y_pred_all[y_pred_all != background_class]), \n",
    "                yticklabels=classes) #np.unique(y_true_all[y_true_all != background_class]))\n",
    "    plt.xlabel('Предсказанные метки')\n",
    "    plt.ylabel('Истинные метки')\n",
    "    plt.title('Матрица путаницы (исключая фон)')\n",
    "    plt.show()\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1, avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc.calculate_metrics = calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision, avg_recall, avg_f1, avg_iou = calc.calculate_metrics(images1, images2, segmentation_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern_env_with_sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
